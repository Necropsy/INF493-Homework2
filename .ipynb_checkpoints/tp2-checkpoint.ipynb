{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho prático II - Classificação\n",
    "\n",
    "O objetivo deste trabalho é praticar os conceitos de aprendizado supervisionado que vimos em sala.\n",
    "\n",
    "A sua tarefa será treinar um classificador para um conjunto de dados misterioso (se eu falasses qual é o objetivo do modelo, você encontraria soluções na Internet).\n",
    "\n",
    "Baixe o arquivo [t2.tar.gz](https://drive.google.com/file/d/125plHKUzFGxHjjCiVJcTQG2bPG_zgDNV/view?usp=sharing). Descoprima este arquivo para encontrar outros quatro. Os arquivos `train_X.csv` e `train_y.csv` possuem os dados que você deve usar para treinar o modelo. O arquivo `test_X.csv` possui os objetos para os quais você deve encontrar as classes (testar o modelo). Por fim, o arquivo `test_example_y.csv` é um exemplo de como sua solução final deve ser organizada.\n",
    "\n",
    "Cada linha dos arquivos `train_X.csv` e `test_X.csv` tem 15 campos descrevendo um objeto misterioso. O campo `id` representa o identificador do objeto, sendo que este campo não deve ser considerado em seu modelo. Os atributos a serem usados no modelo são os 14 campos rotulados de de `a` até `n`. Desses atributos:\n",
    "- `b`, `d`, `f`, `g`, `h`, `i`, `j` e `n` são categóricos; e\n",
    "- `a`, `c`, `e`, `k`, `l` e `m` são numéricos.\n",
    "\n",
    "Cada linha do arquivo `train_y.csv` possui dois campos. O primeiro é o identificador de um objeto do arquivo `train_X.csv` e o segundo é a classe do respectivo objeto (0 ou 1).\n",
    "\n",
    "Seu objetivo é encontrar as classes dos objetos do arquivo `test_X.csv` e mostrar como chegou em sua solução! Os dados do arquivo de teste foram obtido a partir de uma amostra aleatório do todo. Ou seja, um modelo bem treinado, e sem _overfitting_, em `train_X.csv` e `train_y.csv` se sairá bem em `test_X.csv`.\n",
    "\n",
    "**Data de entrega:** dia 4 de julho de 2018.\n",
    "\n",
    "**Grupo:** de até 3 pessoas, mas duas pessoas do mesmo grupo no trabalho 1 não podem pertencer ao mesmo grupo nesse trabalho.\n",
    "\n",
    "**Valor:** 20% da nota do semestre.\n",
    "\n",
    "Os três seguintes pontos descrevem o que obrigatoriamente deve ser entregue, com seu respectivo valor.\n",
    "\n",
    "1 - **[10 pontos]** Este notebook com todo seu código e resultados (números, tabelas e gráficos). Você pode usar qualquer um dos métodos que estudamos ou alguma de suas variações próximas. Se estiver na dúvida se pode usar um método, basta perguntas no Piazza. Comentários e justificativas no notebook não serão considerados para sua nota.\n",
    "O notebook deve ser enviado para o email do professor.\n",
    "\n",
    "2 - **[8 pontos]** Um relatório digitado contendo: capa, introdução, metodologia, resultados, conclusão e referências. O relatório deve ter no máximo 10 páginas, com coluna simples, fonte 11, espaçamento 1.5 e margens de 2cm. A seção de metodologia deve conter uma descrição detalhada dos passos seguidos (não incluir código no relatório). A seção de resultados deve conter obrigatoriamente: uma caracterização descritiva dos dados, matriz de confusão das predições, _precision_, _recall_, _F1 score_ e acurácia. Todas as métricas de predição devem ser calculadas a partir dos arquivos de treinamento por meio de validação cruzada.\n",
    "O relatório deve ser enviado para o email do professor.\n",
    "\n",
    "3 - **[2 pontos + equivalente a lista extra pela classificação]** A sua predição final do arquivo `test_X.csv` deve ser enviada para o professor por email. O formato deve ser o mesmo do arquivo `train_y.csv`, assim como exemplificado em `test_example_y.csv` (mas repare que as classes desse último arquivo foram gerados de forma aleatória). Em outras palavras, o arquivo a ser entregue deve ter dois campos. O campo `id` é o identificador do objeto em `test_X.csv` e o campo `label` é a classe que seu modelo encontrou para o objeto em questão. A primeira linha do arquivo deve conter os nomes das colunas.\n",
    "A entrega desse arquivo é obrigatória e vale dois pontos. Além disso, o trabalho com maior _F1 score_ ganhará o equivalente a 100% de uma lista extra. O trabalho com o pior _F1 score_ não ganhará nota extra alguma. Os demais trabalhos terão nota proporcional.\n",
    "O professor se reserva o direito de anular esse quesito (nota extra) se houver indícios de má conduta durante a competição.\n",
    "\n",
    "**Kaggle:** Estou tentando criar uma competição para esse trabalho na plataforma _Kaggle_. Se eu conseguir, compartilho o _link_ com você no _Piazza_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura dos dados\n",
    "train_X = pd.read_csv(\"train_X.csv\")\n",
    "train_Y = pd.read_csv(\"train_y.csv\")\n",
    "x = pd.read_csv(\"test_X.csv\")\n",
    "y = pd.read_csv(\"test_example_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste dos dados (binariza dados categóricos no dataset)\n",
    "#b, d, f, g, h, i, j e n são categóricos\n",
    "#a, c, e, k, l e m são numéricos\n",
    "def binarizeData(data, columns):\n",
    "    binData = data.drop(columns, axis=1)\n",
    "    for col in columns:\n",
    "        l = pp.LabelBinarizer()\n",
    "        auxData = pd.DataFrame(l.fit_transform(data[col]))\n",
    "        colNames = [col + '_' + str(i) for i in range(len(auxData.columns))]\n",
    "        auxData.columns = colNames\n",
    "        binData[colNames] = auxData\n",
    "    return binData\n",
    "\n",
    "#train_X --> 40222 rows × 15 columns\n",
    "#x --> 5000 rows × 15 columns\n",
    "dataFrame = pd.concat([train_X, x])\n",
    "dataFrame_bin = binarizeData(dataFrame, [\"b\",\"d\",\"f\",\"g\",\"h\",\"i\",\"j\",\"n\"])\n",
    "\n",
    "#Normalizando os dados\n",
    "scaler = pp.MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(dataFrame_bin.loc[:,'a':]))\n",
    "\n",
    "#Definição dos conjuntos\n",
    "baseTrain = data.loc[:40221,:]\n",
    "predict = data.loc[40222:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = train_Y.loc[:,'label':]\n",
    "train_x, test_x, train_y, test_y = ms.train_test_split(baseTrain, classe[\"label\"].values, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação dos metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando os dados (usando SVM)\n",
    "clf1 = svm.SVC(kernel=\"rbf\", C=0.1, degree=2).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "#Treinando os dados (usando Árvore de decisão)\n",
    "clf2 = tree.DecisionTreeClassifier().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble as ens\n",
    "#Treinando os dados (usando Florestas aleatórias)\n",
    "clf3 = ens.RandomForestClassifier(n_estimators=10000, criterion='entropy', warm_start=True, n_jobs=-1).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes as nb\n",
    "#Treinando os dados (usando Naive Bayes)\n",
    "clf4 = nb.BernoulliNB(alpha=0.01, binarize=0.4, class_prior=None, fit_prior=True).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('precision: 0.53078', 'recall: 0.79231', 'f1_score: 0.63570', 'accuracy: 0.77695')\n",
      "\n",
      "Matriz de Confusão:\n",
      "\n",
      "[[17599  5064]\n",
      " [ 1599  5904]]\n"
     ]
    }
   ],
   "source": [
    "#Predizendo a classe do conjunto de teste\n",
    "def score(clf, pred, target):\n",
    "    predictData = clf.predict(pred)\n",
    "    return (\"precision: \"+str('{:.5f}'.format(mt.precision_score(target, predictData))), \"recall: \"+str('{:.5f}'.format(mt.recall_score(target, predictData))), \"f1_score: \"+str('{:.5f}'.format(mt.f1_score(target, predictData))), \"accuracy: \"+str('{:.5f}'.format(mt.accuracy_score(target, predictData))))\n",
    "\n",
    "print(score(clf4, test_x, test_y))\n",
    "\n",
    "#Plot da matriz de confusão\n",
    "#Classificadores disponiveis: {clf(x): 1 <= x <= 4}\n",
    "#1-SVM; 2-decision tree; 3-random forest; 4-naive bayes.\n",
    "print(\"\\nMatriz de Confusão:\\n\")\n",
    "print(mt.confusion_matrix(train_y, clf4.predict(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela de Resultados:\n",
    "\n",
    "|Método       |Score (predição, precision, recall, F1 score e acurácia)             |\n",
    "|-------------|---------------------------------------------------------------------|\n",
    "|svm          |(0.71990, 0.47449, 0.57199, 0.82558)                                 |\n",
    "|decision tree|(0.61341, 0.62955, 0.62138, 0.81156)                                 |\n",
    "|random forest|(0.74017, 0.64008, 0.68650, 0.85640)                                 |\n",
    "|naive bayes  |(0.53078, 0.79231, 0.63570, 0.77695)                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração do arquivo para envio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdId = x[\"id\"]\n",
    "pdData = pd.DataFrame(clf3.predict(predict), columns=[\"label\"])\n",
    "send = pd.concat([pdId, pdData], axis=1)\n",
    "send.to_csv(\"81814_Solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
